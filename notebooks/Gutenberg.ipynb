{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gutenberg.acquire import load_etext\n",
    "from gutenberg.cleanup import strip_headers\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_sentences(st):\n",
    "    sentences = re.split(r'([.?!])\\s*', st)\n",
    "    sentences = [s+p for s,p in zip(sentences[::2], sentences[1::2])]\n",
    "    if sentences[-1]:\n",
    "        return sentences\n",
    "    else:\n",
    "        return sentences[:-1]\n",
    "    \n",
    "def extract_sentences(text):\n",
    "    return split_sentences(\n",
    "        ' '.join([\n",
    "            re.sub(\n",
    "                r'\\[\\d+\\]', '', re.sub(r'^\\s+', '', l)\n",
    "            ) for l in text.split('\\r\\n') \n",
    "            if (l.startswith('  ') and ('*' not in l))\n",
    "        ])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Japanese Prints  By John Gould Fletcher\n",
    "text = strip_headers(load_etext(27199)).strip()\n",
    "sentences += split_sentences(\n",
    "    ' '.join([\n",
    "        l.replace('    ', '') for l in text[text.index('_Part I_'):].split('\\r\\n') if l.startswith('    ')\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TS Eliot\n",
    "text = strip_headers(load_etext(1567)).strip()\n",
    "sentences += split_sentences(\n",
    "    ' '.join([\n",
    "        re.sub(r'^\\s+', '', l) for l in text[899:].split('\\r\\n') if l.startswith('    ')\n",
    "    ])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Child's Garden of Verses, by Robert Louis Stevenson\n",
    "text = strip_headers(load_etext(19722)).strip()\n",
    "sentences += extract_sentences(text[text.index('    In winter I get up at night'):])\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE COLLECTED POEMS OF RUPERT BROOKE\n",
    "text = strip_headers(load_etext(262)).strip()\n",
    "sentences += extract_sentences(text[text.index('   Here in the dark, O heart;'):])\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FREEDOM, TRUTH AND BEAUTY\n",
    "text = strip_headers(load_etext(20174)).strip()\n",
    "sentences += extract_sentences(text[text.index('  What lineage so noble as from Sires,'):])\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LYRICS OF EARTH\n",
    "text = strip_headers(load_etext(12664)).strip()\n",
    "sentences += extract_sentences(text[text.index('    Mother, to whose valiant will,'):])\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Book of Sword Blades and Poppy Seed,\n",
    "text = strip_headers(load_etext(1020)).strip()\n",
    "sentences += extract_sentences(text[text.index('      A drifting, April, twilight sky,'):])\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Book of A Dome of Many-Coloured Glass\n",
    "text = strip_headers(load_etext(261)).strip()\n",
    "sentences += extract_sentences(text[text.index('          Before the Altar, bowed, he stands'):])\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A HUNDRED AND SEVENTY CHINESE POEMS\n",
    "text = strip_headers(load_etext(42290)).strip()\n",
    "sentences += extract_sentences(text[text.index('    â€œWe grasp our battle-spears: we don our breast-plates of hide.'):])\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A HUNDRED AND SEVENTY CHINESE POEMS\n",
    "text = strip_headers(load_etext(7889)).strip()\n",
    "sentences += extract_sentences(text[text.index('  Here\\'s where'):])\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6284"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import inflect\n",
    "inflect_engine = inflect.engine()\n",
    "\n",
    "# Load Phonemes\n",
    "\n",
    "WORDS = {}\n",
    "\n",
    "# Standard Dict\n",
    "with open('cmudict.dict.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        word, phonemes = line.strip().split(' ', 1)\n",
    "        word = re.match(r'([^\\(\\)]*)(\\(\\d\\))*', word).groups()[0]\n",
    "        phonemes = phonemes.split(' ')\n",
    "        syllables = sum([re.match(r'.*\\d', p) is not None for p in phonemes])\n",
    "        #print(word, phonemes, syllables)\n",
    "        if word not in WORDS:\n",
    "            WORDS[word] = []\n",
    "        WORDS[word].append({\n",
    "            'phonemes': phonemes,\n",
    "            'syllables': syllables\n",
    "        })\n",
    "        \n",
    "# Load custom phonemes\n",
    "vowels = ['AA', 'AE', 'AH', 'AO', 'AW', 'AX', 'AXR', 'AY', 'EH', 'ER', 'EY', 'IH', 'IX', 'IY', 'OW', 'OY', 'UH', 'UW', 'UX']\n",
    "\n",
    "with open('8659.dict.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        word, phonemes = line.strip().split('\\t', 1)\n",
    "        word = re.match(r'([^\\(\\)]*)(\\(\\d\\))*', word).groups()[0].lower()\n",
    "        phonemes = phonemes.split(' ')\n",
    "        syllables = sum([(p in vowels) for p in phonemes])\n",
    "        \n",
    "        if word not in WORDS:\n",
    "            WORDS[word] = []\n",
    "        WORDS[word].append({\n",
    "            'phonemes': phonemes,\n",
    "            'syllables': syllables\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
