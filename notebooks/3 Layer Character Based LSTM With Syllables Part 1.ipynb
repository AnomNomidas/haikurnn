{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Dropout, LSTM, Embedding, Reshape, Input, InputLayer, Concatenate, Lambda, Add\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Memorial Day --',\n",
       " 'a shadow for each',\n",
       " 'white cross',\n",
       " '5',\n",
       " '5',\n",
       " '2',\n",
       " 'MMemorial Day --\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       " 'Memorial Day --a\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       " 'aa shadow for each\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       " 'a shadow for eachw\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       " 'wwhite cross\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       " 'white cross\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([\n",
    "    pd.read_csv('haikus_with_syllables.csv', encoding='latin1'),\n",
    "    pd.read_csv('haikus_sballas8_with_syllables.csv', encoding='latin1'),\n",
    "    pd.read_csv('haiku_unim.csv', encoding='latin1')\n",
    "]).reset_index(drop=True)\n",
    "df = df[df['lang'] == 'en'].copy()\n",
    "df = df[~pd.isnull(df['0']) & ~pd.isnull(df['1']) & ~pd.isnull(df['2'])].copy()\n",
    "df = df[~pd.isnull(df['0_syllables']) & ~pd.isnull(df['1_syllables']) & ~pd.isnull(df['2_syllables'])].copy()\n",
    "\n",
    "# Duplicate lines with ambiguous syllable counts\n",
    "lines = set([0, 1, 2])\n",
    "\n",
    "for i in range(3):\n",
    "    lines.remove(i)\n",
    "    df = df[[\n",
    "        '0', '1', '2',\n",
    "        #'1_syllables', '2_syllables'\n",
    "    ] + ['%s_syllables' % j for j in lines]].join(\n",
    "        df['%s_syllables' % i].str.split(\n",
    "            ',', expand=True\n",
    "        ).stack(-1).reset_index(\n",
    "            level=1, drop=True\n",
    "        ).rename('%s_syllables' % i)\n",
    "    ).drop_duplicates()\n",
    "    lines.add(i)\n",
    "\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_line_len = int(max([df['%s' % i].str.len().quantile(.99) for i in range(3)]))\n",
    "df = df[\n",
    "    (df['0'].str.len() <= max_line_len) & \n",
    "    (df['1'].str.len() <= max_line_len) & \n",
    "    (df['2'].str.len() <= max_line_len)\n",
    "]\n",
    "\n",
    "for i in range(3):\n",
    "    #i = str(i)\n",
    "    df['%s_in' % i] = df[str(i)].str[0] + df[str(i)].str.pad(max_line_len, 'right', '\\n')\n",
    "    df['%s_out' % i] = df[str(i)].str.pad(max_line_len, 'right', '\\n') + ('\\n' if i == 2 else df[str(i+1)].str[0])\n",
    "    #df['%s_out' % i] = df[str(i)] + ('\\n' if i == 2 else df[str(i+1)].str[0])\n",
    "    #df['%s_out' % i] = df['%s_out' % i].str.pad(max_line_len + 1, 'right', '\\n')\n",
    "    \n",
    "max_line_len += 1\n",
    "\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = df[['0_in', '1_in', '2_in']].values\n",
    "\n",
    "t = Tokenizer(filters='', char_level=True)\n",
    "t.fit_on_texts(inputs.flatten())\n",
    "n_tokens = len(t.word_counts) + 1\n",
    "\n",
    "X = np_utils.to_categorical([\n",
    "    t.texts_to_sequences(inputs[:,i]) for i in range(3)\n",
    "], num_classes=n_tokens)\n",
    "\n",
    "outputs = df[['0_out', '1_out', '2_out']].values\n",
    "\n",
    "#t = Tokenizer(filters='', char_level=True)\n",
    "#t.fit_on_texts(outputs.flatten())\n",
    "Y = np_utils.to_categorical([\n",
    "    t.texts_to_sequences(outputs[:,i]) for i in range(3)\n",
    "], num_classes=n_tokens)\n",
    "\n",
    "n_tokens = len(t.word_counts) + 1\n",
    "\n",
    "X_syllables = df[['0_syllables', '1_syllables', '2_syllables']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                                      Output Shape                                Param #                 Connected to                                                      \n",
      "========================================================================================================================================================================================================\n",
      "syllables_line_0 (InputLayer)                                     (None, 1)                                   0                                                                                         \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "input_line_0 (InputLayer)                                         (None, None, 64)                            0                                                                                         \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "syllable_dense_0 (Dense)                                          (None, 512)                                 1024                    syllables_line_0[0][0]                                            \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "syllables_line_1 (InputLayer)                                     (None, 1)                                   0                                                                                         \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "lstm_0 (LSTM)                                                     [(None, None, 512), (None, 512), (None, 512 1181696                 input_line_0[0][0]                                                \n",
      "                                                                                                                                      syllable_dense_0[0][0]                                            \n",
      "                                                                                                                                      syllable_dense_0[0][0]                                            \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "syllable_dense_1 (Dense)                                          (None, 512)                                 1024                    syllables_line_1[0][0]                                            \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "input_line_1 (InputLayer)                                         (None, None, 64)                            0                                                                                         \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "add_h_1 (Add)                                                     (None, 512)                                 0                       lstm_0[0][1]                                                      \n",
      "                                                                                                                                      syllable_dense_1[0][0]                                            \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "add_c_1 (Add)                                                     (None, 512)                                 0                       lstm_0[0][2]                                                      \n",
      "                                                                                                                                      syllable_dense_1[0][0]                                            \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "syllables_line_2 (InputLayer)                                     (None, 1)                                   0                                                                                         \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                                                     [(None, None, 512), (None, 512), (None, 512 1181696                 input_line_1[0][0]                                                \n",
      "                                                                                                                                      add_h_1[0][0]                                                     \n",
      "                                                                                                                                      add_c_1[0][0]                                                     \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "syllable_dense_2 (Dense)                                          (None, 512)                                 1024                    syllables_line_2[0][0]                                            \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "input_line_2 (InputLayer)                                         (None, None, 64)                            0                                                                                         \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "add_h_2 (Add)                                                     (None, 512)                                 0                       lstm_1[0][1]                                                      \n",
      "                                                                                                                                      syllable_dense_2[0][0]                                            \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "add_c_2 (Add)                                                     (None, 512)                                 0                       lstm_1[0][2]                                                      \n",
      "                                                                                                                                      syllable_dense_2[0][0]                                            \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                                                     [(None, None, 512), (None, 512), (None, 512 1181696                 input_line_2[0][0]                                                \n",
      "                                                                                                                                      add_h_2[0][0]                                                     \n",
      "                                                                                                                                      add_c_2[0][0]                                                     \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "output_0 (Dense)                                                  (None, None, 64)                            32832                   lstm_0[0][0]                                                      \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "output_1 (Dense)                                                  (None, None, 64)                            32832                   lstm_1[0][0]                                                      \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "output_2 (Dense)                                                  (None, None, 64)                            32832                   lstm_2[0][0]                                                      \n",
      "========================================================================================================================================================================================================\n",
      "Total params: 3,646,656\n",
      "Trainable params: 3,646,656\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 512\n",
    "\n",
    "# Keras Model\n",
    "\n",
    "inputs = [Input(shape=(None, n_tokens), name='input_line_%s' % i) for i in range(3)]\n",
    "\n",
    "syllables = [Input(shape=(1,), name='syllables_line_%s' % i) for i in range(3)]\n",
    "syllable_denses = [Dense(latent_dim, activation='relu', name='syllable_dense_%s' % i) for i in range(3)]\n",
    "syllable_dense_outputs = [syllable_denses[i](syllables[i]) for i in range(3)]\n",
    "\n",
    "lstms = [LSTM(latent_dim, return_state=True, return_sequences=True, name='lstm_%s' % i) for i in range(3)]\n",
    "\n",
    "lstm_out, lstm_h, lstm_c = [None, None, None], [None, None, None], [None, None, None]\n",
    "for i in range(3):\n",
    "    if i > 0:\n",
    "        lstm_out[i], lstm_h[i], lstm_c[i] = lstms[i](inputs[i], initial_state=[\n",
    "            Add(name='add_h_%s' % i)([\n",
    "                lstm_h[i-1],\n",
    "                syllable_dense_outputs[i]\n",
    "            ]),\n",
    "            Add(name='add_c_%s' % i)([\n",
    "                lstm_c[i-1],\n",
    "                syllable_dense_outputs[i]\n",
    "            ])\n",
    "        ])\n",
    "    else:\n",
    "        lstm_out[i], lstm_h[i], lstm_c[i] = lstms[i](inputs[i], initial_state=[\n",
    "            syllable_dense_outputs[i], syllable_dense_outputs[i]\n",
    "        ])\n",
    "        \n",
    "denses = [Dense(n_tokens, activation='softmax', name='output_%s' % i) for i in range(3)]\n",
    "outputs = [denses[i](lstm_out[i]) for i in range(3)]\n",
    "\n",
    "# Enforce number of chars per line\n",
    "#counter = Lambda(lambda x: K.sum(K.cast(K.less(K.argmax(x, axis=2), 60), K.floatx()), axis=1, keepdims=True))\n",
    "#counts = [counter(i) for i in outputs]\n",
    "\n",
    "#model = Model(inputs, outputs + counts)\n",
    "\n",
    "model = Model(inputs + syllables, outputs)\n",
    "\n",
    "# Use categorical for the character outputs and MSE for the counts\n",
    "#model.compile(optimizer='rmsprop', loss=['categorical_crossentropy']*3 + ['mean_squared_error']*3)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.summary(line_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  7, 21, 10,  9,  8, 17,  2, 10,  5,  9,  8,  2, 25,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(X[0][1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "24777/24777 [==============================] - 736s 30ms/step - loss: 0.5457 - output_0_loss: 0.1952 - output_1_loss: 0.2249 - output_2_loss: 0.1256\n",
      "Epoch 2/1000\n",
      "24777/24777 [==============================] - 788s 32ms/step - loss: 0.5386 - output_0_loss: 0.1934 - output_1_loss: 0.2217 - output_2_loss: 0.1235\n",
      "Epoch 3/1000\n",
      "24777/24777 [==============================] - 768s 31ms/step - loss: 0.5331 - output_0_loss: 0.1920 - output_1_loss: 0.2191 - output_2_loss: 0.1220\n",
      "Epoch 4/1000\n",
      "24777/24777 [==============================] - 809s 33ms/step - loss: 0.5265 - output_0_loss: 0.1904 - output_1_loss: 0.2157 - output_2_loss: 0.1203\n",
      "Epoch 5/1000\n",
      "24777/24777 [==============================] - 754s 30ms/step - loss: 0.5208 - output_0_loss: 0.1890 - output_1_loss: 0.2134 - output_2_loss: 0.1184\n",
      "Epoch 6/1000\n",
      "24777/24777 [==============================] - 761s 31ms/step - loss: 0.5162 - output_0_loss: 0.1879 - output_1_loss: 0.2112 - output_2_loss: 0.1170\n",
      "Epoch 7/1000\n",
      "24777/24777 [==============================] - 758s 31ms/step - loss: 0.5108 - output_0_loss: 0.1867 - output_1_loss: 0.2086 - output_2_loss: 0.1155\n",
      "Epoch 8/1000\n",
      "24777/24777 [==============================] - 768s 31ms/step - loss: 0.5059 - output_0_loss: 0.1855 - output_1_loss: 0.2065 - output_2_loss: 0.1139\n",
      "Epoch 9/1000\n",
      "24777/24777 [==============================] - 747s 30ms/step - loss: 0.5013 - output_0_loss: 0.1844 - output_1_loss: 0.2046 - output_2_loss: 0.1123\n",
      "Epoch 10/1000\n",
      "24777/24777 [==============================] - 768s 31ms/step - loss: 0.4974 - output_0_loss: 0.1836 - output_1_loss: 0.2027 - output_2_loss: 0.1111\n",
      "Epoch 11/1000\n",
      "24777/24777 [==============================] - 780s 31ms/step - loss: 0.4932 - output_0_loss: 0.1825 - output_1_loss: 0.2007 - output_2_loss: 0.1100\n",
      "Epoch 12/1000\n",
      "24777/24777 [==============================] - 763s 31ms/step - loss: 0.4894 - output_0_loss: 0.1817 - output_1_loss: 0.1988 - output_2_loss: 0.1089\n",
      "Epoch 13/1000\n",
      "24777/24777 [==============================] - 755s 30ms/step - loss: 0.4852 - output_0_loss: 0.1804 - output_1_loss: 0.1974 - output_2_loss: 0.1073\n",
      "Epoch 14/1000\n",
      "24777/24777 [==============================] - 774s 31ms/step - loss: 0.4811 - output_0_loss: 0.1797 - output_1_loss: 0.1953 - output_2_loss: 0.1062\n",
      "Epoch 15/1000\n",
      "24777/24777 [==============================] - 780s 31ms/step - loss: 0.4772 - output_0_loss: 0.1786 - output_1_loss: 0.1936 - output_2_loss: 0.1050\n",
      "Epoch 16/1000\n",
      "24777/24777 [==============================] - 773s 31ms/step - loss: 0.4743 - output_0_loss: 0.1781 - output_1_loss: 0.1919 - output_2_loss: 0.1043\n",
      "Epoch 17/1000\n",
      "24777/24777 [==============================] - 782s 32ms/step - loss: 0.4705 - output_0_loss: 0.1773 - output_1_loss: 0.1904 - output_2_loss: 0.1028\n",
      "Epoch 18/1000\n",
      "24777/24777 [==============================] - 771s 31ms/step - loss: 0.4669 - output_0_loss: 0.1763 - output_1_loss: 0.1887 - output_2_loss: 0.1018\n",
      "Epoch 19/1000\n",
      "24777/24777 [==============================] - 796s 32ms/step - loss: 0.4628 - output_0_loss: 0.1756 - output_1_loss: 0.1868 - output_2_loss: 0.1004\n",
      "Epoch 20/1000\n",
      "24777/24777 [==============================] - 790s 32ms/step - loss: 0.4603 - output_0_loss: 0.1748 - output_1_loss: 0.1860 - output_2_loss: 0.0994\n",
      "Epoch 21/1000\n",
      "24777/24777 [==============================] - 783s 32ms/step - loss: 0.4573 - output_0_loss: 0.1743 - output_1_loss: 0.1845 - output_2_loss: 0.0985\n",
      "Epoch 22/1000\n",
      "24777/24777 [==============================] - 787s 32ms/step - loss: 0.4539 - output_0_loss: 0.1733 - output_1_loss: 0.1831 - output_2_loss: 0.0975\n",
      "Epoch 23/1000\n",
      "24777/24777 [==============================] - 783s 32ms/step - loss: 0.4509 - output_0_loss: 0.1726 - output_1_loss: 0.1819 - output_2_loss: 0.0964\n",
      "Epoch 24/1000\n",
      "24777/24777 [==============================] - 825s 33ms/step - loss: 0.4485 - output_0_loss: 0.1721 - output_1_loss: 0.1807 - output_2_loss: 0.0956\n",
      "Epoch 25/1000\n",
      "24777/24777 [==============================] - 795s 32ms/step - loss: 0.4455 - output_0_loss: 0.1714 - output_1_loss: 0.1794 - output_2_loss: 0.0948\n",
      "Epoch 26/1000\n",
      "24777/24777 [==============================] - 791s 32ms/step - loss: 0.4422 - output_0_loss: 0.1705 - output_1_loss: 0.1782 - output_2_loss: 0.0934\n",
      "Epoch 27/1000\n",
      "24777/24777 [==============================] - 773s 31ms/step - loss: 0.4391 - output_0_loss: 0.1701 - output_1_loss: 0.1763 - output_2_loss: 0.0928\n",
      "Epoch 28/1000\n",
      "24777/24777 [==============================] - 771s 31ms/step - loss: 0.4367 - output_0_loss: 0.1692 - output_1_loss: 0.1754 - output_2_loss: 0.0922\n",
      "Epoch 29/1000\n",
      "24777/24777 [==============================] - 829s 33ms/step - loss: 0.4344 - output_0_loss: 0.1687 - output_1_loss: 0.1744 - output_2_loss: 0.0913\n",
      "Epoch 30/1000\n",
      "24777/24777 [==============================] - 787s 32ms/step - loss: 0.4319 - output_0_loss: 0.1681 - output_1_loss: 0.1732 - output_2_loss: 0.0906\n",
      "Epoch 31/1000\n",
      "24777/24777 [==============================] - 791s 32ms/step - loss: 0.4283 - output_0_loss: 0.1676 - output_1_loss: 0.1716 - output_2_loss: 0.0891\n",
      "Epoch 32/1000\n",
      "24777/24777 [==============================] - 829s 33ms/step - loss: 0.4273 - output_0_loss: 0.1672 - output_1_loss: 0.1711 - output_2_loss: 0.0891\n",
      "Epoch 33/1000\n",
      "24777/24777 [==============================] - 790s 32ms/step - loss: 0.4245 - output_0_loss: 0.1667 - output_1_loss: 0.1698 - output_2_loss: 0.0880\n",
      "Epoch 34/1000\n",
      "24777/24777 [==============================] - 814s 33ms/step - loss: 0.4217 - output_0_loss: 0.1660 - output_1_loss: 0.1683 - output_2_loss: 0.0874\n",
      "Epoch 35/1000\n",
      "24777/24777 [==============================] - 774s 31ms/step - loss: 0.4195 - output_0_loss: 0.1652 - output_1_loss: 0.1678 - output_2_loss: 0.0865\n",
      "Epoch 36/1000\n",
      "24777/24777 [==============================] - 790s 32ms/step - loss: 0.4169 - output_0_loss: 0.1650 - output_1_loss: 0.1663 - output_2_loss: 0.0856\n",
      "Epoch 37/1000\n",
      "24777/24777 [==============================] - 828s 33ms/step - loss: 0.4149 - output_0_loss: 0.1647 - output_1_loss: 0.1652 - output_2_loss: 0.0850\n",
      "Epoch 38/1000\n",
      "24777/24777 [==============================] - 785s 32ms/step - loss: 0.4126 - output_0_loss: 0.1639 - output_1_loss: 0.1644 - output_2_loss: 0.0843\n",
      "Epoch 39/1000\n",
      "24777/24777 [==============================] - 822s 33ms/step - loss: 0.4104 - output_0_loss: 0.1640 - output_1_loss: 0.1634 - output_2_loss: 0.0830\n",
      "Epoch 40/1000\n",
      "24777/24777 [==============================] - 812s 33ms/step - loss: 0.4078 - output_0_loss: 0.1631 - output_1_loss: 0.1626 - output_2_loss: 0.0821\n",
      "Epoch 41/1000\n",
      "24777/24777 [==============================] - 793s 32ms/step - loss: 0.4057 - output_0_loss: 0.1627 - output_1_loss: 0.1613 - output_2_loss: 0.0817\n",
      "Epoch 42/1000\n",
      "24777/24777 [==============================] - 776s 31ms/step - loss: 0.4039 - output_0_loss: 0.1620 - output_1_loss: 0.1607 - output_2_loss: 0.0812\n",
      "Epoch 43/1000\n",
      "24777/24777 [==============================] - 815s 33ms/step - loss: 0.4016 - output_0_loss: 0.1615 - output_1_loss: 0.1599 - output_2_loss: 0.0803\n",
      "Epoch 44/1000\n",
      "24777/24777 [==============================] - 811s 33ms/step - loss: 0.3997 - output_0_loss: 0.1612 - output_1_loss: 0.1588 - output_2_loss: 0.0796\n",
      "Epoch 45/1000\n",
      "21504/24777 [=========================>....] - ETA: 1:57 - loss: 0.3952 - output_0_loss: 0.1600 - output_1_loss: 0.1571 - output_2_loss: 0.0781"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-ea9ea7ba9952>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mX_syllables\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_syllables\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_syllables\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m ], [Y[0], Y[1], Y[2]], batch_size=64, epochs=1000)\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Jeremy\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\Users\\Jeremy\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jeremy\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jeremy\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m                                 session)\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jeremy\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit([\n",
    "    X[0], X[1], X[2],\n",
    "    X_syllables[:,0], X_syllables[:,1], X_syllables[:,2]\n",
    "], [Y[0], Y[1], Y[2]], batch_size=64, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "generator_syllables_0 (InputLay (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "generator_in_h_0 (InputLayer)   (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "generator_syllable_dense_0 (Den (None, 512)          1024        generator_syllables_0[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "generator_in_c_0 (InputLayer)   (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "generator_input_0 (InputLayer)  (None, None, 64)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "generator_add_h_0 (Add)         (None, 512)          0           generator_in_h_0[0][0]           \n",
      "                                                                 generator_syllable_dense_0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "generator_add_c_0 (Add)         (None, 512)          0           generator_in_c_0[0][0]           \n",
      "                                                                 generator_syllable_dense_0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "generator_lstm_0 (LSTM)         [(None, None, 512),  1181696     generator_input_0[0][0]          \n",
      "                                                                 generator_add_h_0[0][0]          \n",
      "                                                                 generator_add_c_0[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, None, 64)     32832       generator_lstm_0[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 1,215,552\n",
      "Trainable params: 1,215,552\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator_inputs = [Input(shape=(None, n_tokens), name='generator_input_%s' % i) for i in range(3)]\n",
    "generator_inputs_h = [Input(shape=(latent_dim,), name='generator_in_h_%s' % i) for i in range(3)]\n",
    "generator_inputs_c = [Input(shape=(latent_dim,), name='generator_in_c_%s' % i) for i in range(3)]\n",
    "generator_lstms = [LSTM(latent_dim, return_state=True, return_sequences=True, name='generator_lstm_%s' % i) for i in range(3)]\n",
    "generator_lstm_out, generator_lstm_h, generator_lstm_c = [None, None, None], [None, None, None], [None, None, None]\n",
    "generator_denses = [Dense(n_tokens, activation='softmax') for i in range(3)]\n",
    "\n",
    "generator_syllables = [Input(shape=(1,), name='generator_syllables_%s' % i) for i in range(3)]\n",
    "generator_syllable_denses = [Dense(latent_dim, activation='relu', name='generator_syllable_dense_%s' % i) for i in range(3)]\n",
    "#syllable_dense_outputs = [syllable_denses[i](syllables[i]) for i in range(3)]\n",
    "\n",
    "generator_syllable_dense_outputs = []\n",
    "generator_outputs = []\n",
    "generator_models = []\n",
    "\n",
    "for i in range(3):\n",
    "    generator_syllable_dense_outputs.append(generator_syllable_denses[i](generator_syllables[i]))\n",
    "    generator_lstm_out[i], generator_lstm_h[i], generator_lstm_c[i] = generator_lstms[i](\n",
    "        generator_inputs[i], initial_state=[\n",
    "            Add(name='generator_add_h_%s' % i)([\n",
    "                generator_inputs_h[i],\n",
    "                generator_syllable_dense_outputs[i]\n",
    "            ]),\n",
    "            Add(name='generator_add_c_%s' % i)([\n",
    "                generator_inputs_c[i],\n",
    "                generator_syllable_dense_outputs[i]\n",
    "            ])\n",
    "        ]\n",
    "    )\n",
    "    generator_outputs.append(generator_denses[i](generator_lstm_out[i]))\n",
    "\n",
    "    generator_models.append(Model(\n",
    "        [generator_inputs[i], generator_syllables[i], generator_inputs_h[i], generator_inputs_c[i]],\n",
    "        [generator_outputs[i], generator_lstm_h[i], generator_lstm_c[i]]\n",
    "    ))\n",
    "\n",
    "    generator_syllable_denses[i].set_weights(syllable_denses[i].get_weights())\n",
    "    generator_lstms[i].set_weights(lstms[i].get_weights())\n",
    "    generator_denses[i].set_weights(denses[i].get_weights())\n",
    "\n",
    "'''# Hook up line 0\n",
    "generator_syllable_dense_outputs = [generator_syllable_denses[0](generator_syllables[0])]\n",
    "generator_lstm_out[0], generator_lstm_h[0], generator_lstm_c[0] = generator_lstms[0](\n",
    "    generator_inputs[0], initial_state=[generator_syllable_dense_outputs[0], generator_syllable_dense_outputs[0]]\n",
    ")\n",
    "generator_outputs = [generator_denses[0](generator_lstm_out[0])]\n",
    "generator_models = [Model([generator_inputs[0], generator_syllables[0]], [generator_outputs[0], generator_lstm_h[0], generator_lstm_c[0]])]\n",
    "\n",
    "# Set weights for line 0\n",
    "generator_syllable_denses[0].set_weights(syllable_denses[0].get_weights())\n",
    "generator_lstms[0].set_weights(lstms[0].get_weights())\n",
    "generator_denses[0].set_weights(denses[0].get_weights())'''\n",
    "\n",
    "generator_models[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "fgenerator_input_0 (InputLayer) (None, None, 64)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "fgenerator_in_h_0 (InputLayer)  (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "fgenerator_in_c_0 (InputLayer)  (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "fgenerator_lstm_0 (LSTM)        [(None, None, 512),  1181696     fgenerator_input_0[0][0]         \n",
      "                                                                 fgenerator_in_h_0[0][0]          \n",
      "                                                                 fgenerator_in_c_0[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, None, 64)     32832       fgenerator_lstm_0[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 1,214,528\n",
      "Trainable params: 1,214,528\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fgenerator_inputs = [Input(shape=(None, n_tokens), name='fgenerator_input_%s' % i) for i in range(3)]\n",
    "fgenerator_inputs_h = [Input(shape=(latent_dim,), name='fgenerator_in_h_%s' % i) for i in range(3)]\n",
    "fgenerator_inputs_c = [Input(shape=(latent_dim,), name='fgenerator_in_c_%s' % i) for i in range(3)]\n",
    "fgenerator_lstms = [LSTM(latent_dim, return_state=True, return_sequences=True, name='fgenerator_lstm_%s' % i) for i in range(3)]\n",
    "fgenerator_lstm_out, fgenerator_lstm_h, fgenerator_lstm_c = [None, None, None], [None, None, None], [None, None, None]\n",
    "fgenerator_denses = [Dense(n_tokens, activation='softmax') for i in range(3)]\n",
    "\n",
    "#fgenerator_syllables = [Input(shape=(1,), name='fgenerator_syllables_%s' % i) for i in range(3)]\n",
    "#fgenerator_syllable_denses = [Dense(latent_dim, activation='relu', name='fgenerator_syllable_dense_%s' % i) for i in range(3)]\n",
    "\n",
    "#fgenerator_syllable_dense_outputs = []\n",
    "fgenerator_outputs = []\n",
    "fgenerator_models = []\n",
    "\n",
    "for i in range(3):\n",
    "    #fgenerator_syllable_dense_outputs.append(fgenerator_syllable_denses[i](fgenerator_syllables[i]))\n",
    "    fgenerator_lstm_out[i], fgenerator_lstm_h[i], fgenerator_lstm_c[i] = fgenerator_lstms[i](\n",
    "        fgenerator_inputs[i], initial_state=[fgenerator_inputs_h[i], fgenerator_inputs_c[i]]\n",
    "        \n",
    "    )\n",
    "    fgenerator_outputs.append(fgenerator_denses[i](fgenerator_lstm_out[i]))\n",
    "\n",
    "    fgenerator_models.append(Model(\n",
    "        [fgenerator_inputs[i], fgenerator_inputs_h[i], fgenerator_inputs_c[i]],\n",
    "        [fgenerator_outputs[i], fgenerator_lstm_h[i], fgenerator_lstm_c[i]]\n",
    "    ))\n",
    "\n",
    "    #generator_syllable_denses[i].set_weights(syllable_denses[i].get_weights())\n",
    "    fgenerator_lstms[i].set_weights(lstms[i].get_weights())\n",
    "    fgenerator_denses[i].set_weights(denses[i].get_weights())\n",
    "\n",
    "fgenerator_models[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " e a r l y   s p r i n g   w a r m t h\n",
      " h e   t o o   m a k e   m e   f i r m   t h a t   b i t t \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " i\n",
      " t i m e   t o   s t o p   a n d   s t a r e\n"
     ]
    }
   ],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "h,c = np.zeros(latent_dim).reshape((1,-1)), np.zeros(latent_dim).reshape((1,-1))\n",
    "#first = 'maw'\n",
    "pattern = [5,7,5]\n",
    "#generator_models[0].reset_states()\n",
    "#generator_lstms[0].reset_states()\n",
    "for i,syllables in enumerate(pattern):\n",
    "    #line = [random.randint(2,21)]\n",
    "    if i == 0:\n",
    "        line = [random.randint(2,21)]\n",
    "    else:\n",
    "        if 1 in line:\n",
    "            line = [line[line.index(1)-1]]\n",
    "        else:\n",
    "            line = [line[-1]]\n",
    "    #line = t.texts_to_sequences(first[i])[0]\n",
    "    #print(line)\n",
    "    \n",
    "    ## FIRST CHAR\n",
    "    def f():\n",
    "        while True:\n",
    "            yield [np_utils.to_categorical(line[-1], num_classes=n_tokens).reshape((1,1,-1)), np.array([syllables]), h, c]\n",
    "    \n",
    "    character, h, c = generator_models[i].predict_generator(f(), steps=1)    \n",
    "    line.append(np.argmax(character))\n",
    "    \n",
    "    ## ALL THE REST (Don't include syllables, use fgenerator)\n",
    "    def f():\n",
    "        while True:\n",
    "            yield [np_utils.to_categorical(line[-1], num_classes=n_tokens).reshape((1,1,-1)), h, c]\n",
    "            \n",
    "    while len(line) < max_line_len:\n",
    "        character, h, c = fgenerator_models[i].predict_generator(f(), steps=1)\n",
    "        line.append(np.argmax(character))\n",
    "        \n",
    "        \n",
    "        #line.append(sample(character[0][0], .1))\n",
    "        #print (np.argmax(character), line[-1])\n",
    "        \n",
    "    #print(line[1:line.index(1)])\n",
    "    #print(line)\n",
    "    text = t.sequences_to_texts([line])[0].strip()[1:]\n",
    "    #print(text[1:])\n",
    "    print(text)\n",
    "    #if 1 in line:\n",
    "    #    #print(t.sequences_to_texts([line[1:line.index(1)]]))\n",
    "    #else:\n",
    "    #    #print(t.sequences_to_texts([line[1:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line[line.index(1)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\\n', 1176567),\n",
       " (' ', 91088),\n",
       " ('e', 70913),\n",
       " ('t', 56983),\n",
       " ('a', 49723),\n",
       " ('s', 49409),\n",
       " ('o', 47840),\n",
       " ('n', 45498),\n",
       " ('i', 44011),\n",
       " ('r', 41508),\n",
       " ('h', 34613),\n",
       " ('l', 29824),\n",
       " ('d', 22763),\n",
       " ('m', 18905),\n",
       " ('g', 18866),\n",
       " ('f', 17798),\n",
       " ('c', 17475),\n",
       " ('u', 16137),\n",
       " ('w', 16076),\n",
       " ('p', 12694),\n",
       " ('b', 11695),\n",
       " ('y', 10017),\n",
       " ('k', 6938),\n",
       " ('-', 4682),\n",
       " ('v', 4642),\n",
       " ('.', 4179),\n",
       " (\"'\", 2211),\n",
       " ('?', 1459),\n",
       " ('z', 964),\n",
       " ('j', 822),\n",
       " ('q', 540),\n",
       " ('x', 503),\n",
       " (',', 317),\n",
       " (':', 122),\n",
       " ('\"', 67),\n",
       " ('~', 61),\n",
       " ('!', 59),\n",
       " ('1', 57),\n",
       " (';', 47),\n",
       " ('2', 45),\n",
       " ('>', 38),\n",
       " ('0', 35),\n",
       " ('<', 30),\n",
       " ('3', 28),\n",
       " ('&', 21),\n",
       " ('4', 19),\n",
       " ('7', 17),\n",
       " ('6', 14),\n",
       " ('5', 14),\n",
       " ('9', 14),\n",
       " ('8', 13),\n",
       " ('é', 6),\n",
       " ('*', 5),\n",
       " ('/', 5),\n",
       " ('(', 3),\n",
       " ('\\xa0', 2),\n",
       " ('[', 2),\n",
       " ('=', 1),\n",
       " ('ä', 1),\n",
       " (']', 1),\n",
       " (')', 1)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(t.word_counts.items()), key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m',\n",
       " 'e',\n",
       " 'o',\n",
       " 'r',\n",
       " 'i',\n",
       " 'a',\n",
       " 'l',\n",
       " ' ',\n",
       " 'd',\n",
       " 'y',\n",
       " '-',\n",
       " '\\n',\n",
       " 's',\n",
       " 'h',\n",
       " 'w',\n",
       " 'f',\n",
       " 'c',\n",
       " 't',\n",
       " 'p',\n",
       " 'n',\n",
       " 'g',\n",
       " 'k',\n",
       " 'b',\n",
       " 'u',\n",
       " 'x',\n",
       " 'q',\n",
       " 'v',\n",
       " 'z',\n",
       " '~',\n",
       " \"'\",\n",
       " '.',\n",
       " 'j',\n",
       " ',',\n",
       " '!',\n",
       " '<',\n",
       " '>',\n",
       " '?',\n",
       " ':',\n",
       " '2',\n",
       " '1',\n",
       " '*',\n",
       " '7',\n",
       " '3',\n",
       " '0',\n",
       " ';',\n",
       " '6',\n",
       " '5',\n",
       " '8',\n",
       " '&',\n",
       " 'é',\n",
       " '\"',\n",
       " '9',\n",
       " '4',\n",
       " '(',\n",
       " '=',\n",
       " 'ä',\n",
       " '\\xa0',\n",
       " '[',\n",
       " ']',\n",
       " '/',\n",
       " ')']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(t.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
